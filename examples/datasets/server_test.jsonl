{"id": "test_001", "input": {"query": "What is machine learning?"}, "output": {"answer": "Machine learning is a subset of artificial intelligence that enables systems to learn and improve from experience without being explicitly programmed. It uses algorithms to analyze data, identify patterns, and make decisions with minimal human intervention."}, "reference": {"expected": "Machine learning is a method of data analysis that automates analytical model building using algorithms that iteratively learn from data."}, "context": [{"text": "Machine learning is a branch of artificial intelligence (AI) and computer science which focuses on the use of data and algorithms to imitate the way that humans learn, gradually improving its accuracy.", "source": "ml_intro.pdf"}]}
{"id": "test_002", "input": {"query": "Explain deep learning"}, "output": {"answer": "Deep learning is a subset of machine learning that uses neural networks with multiple layers (deep neural networks) to progressively extract higher-level features from raw input. It's particularly effective for tasks like image and speech recognition."}, "reference": {"expected": "Deep learning is a type of machine learning based on artificial neural networks with multiple layers."}, "context": [{"text": "Deep learning is part of a broader family of machine learning methods based on artificial neural networks with representation learning. Learning can be supervised, semi-supervised or unsupervised.", "source": "deep_learning_guide.pdf"}]}
{"id": "test_003", "input": {"query": "What is the capital of France?"}, "output": {"answer": "The capital of France is Paris, which is also the country's largest city and a major European cultural center."}, "reference": {"expected": "Paris"}, "context": [{"text": "Paris is the capital and most populous city of France. Since the 17th century, Paris has been one of Europe's major centres of finance, diplomacy, commerce, fashion, science and arts.", "source": "geography_facts.txt"}]}
{"id": "test_004", "input": {"query": "How does a transformer model work in NLP?"}, "output": {"answer": "Transformer models use self-attention mechanisms to process sequences of data in parallel, rather than sequentially like RNNs. They consist of encoder and decoder layers that use multi-head attention to capture relationships between different positions in the input sequence."}, "reference": {"expected": "Transformers use attention mechanisms to weigh the importance of different parts of the input data."}, "context": [{"text": "The Transformer model architecture, introduced in 'Attention Is All You Need', relies entirely on attention mechanisms to draw global dependencies between input and output. It allows for much more parallelization than recurrent architectures.", "source": "transformer_paper.pdf"}]}
{"id": "test_005", "input": {"query": "What is retrieval augmented generation?"}, "output": {"answer": "Retrieval Augmented Generation (RAG) is a technique that combines information retrieval with text generation. It retrieves relevant documents from a knowledge base and uses them as context to generate more accurate and informed responses."}, "reference": {"expected": "RAG combines retrieval of relevant documents with language model generation to produce contextually grounded responses."}, "context": [{"text": "Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks: RAG models combine a retrieval system with a seq2seq model. The retriever provides relevant documents which the generator uses to produce responses.", "source": "rag_explained.pdf"}]}
